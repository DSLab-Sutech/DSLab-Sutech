{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DSLab-Sutech/DSLab-Sutech/blob/main/ViolenceDetection_NoInformationLeak.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3nLcn3VTYsdR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import IPython.display as ipd\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import librosa\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras import layers\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten,BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv2D,SeparableConv2D\n",
        "from keras.layers.convolutional import Conv1D,MaxPooling1D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import LSTM\n",
        "from sklearn import preprocessing\n",
        "from keras import Model\n",
        "from keras.metrics import Precision,Recall,Accuracy\n",
        "import gc\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUO2oRjTll5T",
        "outputId": "4cdfbb18-088d-4d2a-aac8-c4fce3d7c08d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "#connect colab to google drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1cV3BEjJ-GDq"
      },
      "outputs": [],
      "source": [
        "# def print_plot_play(x, Fs, text=''):\n",
        "#     print('%s Fs = %d, x.shape = %s, x.dtype = %s' % (text, Fs, x.shape, x.dtype))\n",
        "#     plt.figure(figsize=(8, 2))\n",
        "#     plt.plot(x, color='gray')\n",
        "#     plt.xlim([0, x.shape[0]])\n",
        "#     plt.xlabel('Time (samples)')\n",
        "#     plt.ylabel('Amplitude')\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "#     ipd.display(ipd.Audio(data=x, rate=Fs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GNqalCV1lzyo"
      },
      "outputs": [],
      "source": [
        "#load voices\n",
        "Data=[]\n",
        "Target=[]\n",
        "Data_test = []\n",
        "Target_test = []\n",
        "sample_rate = 16000          # google say : We recommend a sample rate of at least 16 kHz in the audio files that you use for transcription with Speech-to-Text.\n",
        "slot_length = 10          # each audio slot is slot_length seconds\n",
        "number_of_samples = slot_length * sample_rate\n",
        "overlap = 3       # samples have 'overlap' seconds of overlapping\n",
        "step = overlap * sample_rate\n",
        "for i in range(1,73):\n",
        "  path=r'/content/drive/My Drive/Audio/Nonviolence/Normal' + str(i) + '.mp3'\n",
        "  x, Fs = librosa.load(path, sr=sample_rate)\n",
        "\n",
        "  for j in range(0,len(x),step):\n",
        "    if(j+number_of_samples < len(x)):\n",
        "      Data.append(x[j:j+number_of_samples])\n",
        "      Target.append(0)\n",
        "\n",
        "for i in range(73,91):\n",
        "  path=r'/content/drive/My Drive/Audio/Nonviolence/Normal' + str(i) + '.mp3'\n",
        "  x, Fs = librosa.load(path, sr=sample_rate)\n",
        "\n",
        "  for j in range(0,len(x),step):\n",
        "    if(j+number_of_samples < len(x)):\n",
        "      Data_test.append(x[j:j+number_of_samples])\n",
        "      Target_test.append(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "snPLZskLTc08"
      },
      "outputs": [],
      "source": [
        "#print_plot_play(Data[202], Fs = sample_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KsJuiIqimBlT"
      },
      "outputs": [],
      "source": [
        "for i in range(1,36):\n",
        "  if i==15 or i==16 or i==17:\n",
        "    continue\n",
        "  path=r'/content/drive/My Drive/Audio/Violence/Violence' + str(i) + '.mp3'\n",
        "  x, Fs = librosa.load(path, sr=None)\n",
        "  for j in range(0,len(x),step):\n",
        "    if(j+number_of_samples < len(x)):\n",
        "      Data.append(x[j:j+number_of_samples])\n",
        "      Target.append(1)\n",
        "\n",
        "for i in range(36,45):\n",
        "  if i==15 or i==16 or i==17:\n",
        "    continue\n",
        "  path=r'/content/drive/My Drive/Audio/Violence/Violence' + str(i) + '.mp3'\n",
        "  x, Fs = librosa.load(path, sr=None)\n",
        "  for j in range(0,len(x),step):\n",
        "    if(j+number_of_samples < len(x)):\n",
        "      Data_test.append(x[j:j+number_of_samples])\n",
        "      Target_test.append(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRBfY8l9ng0l",
        "outputId": "4b05f203-ca19-4709-fc91-77ba81bc5e1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "578"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(Target_test)\n",
        "#normalize data\n",
        "#normal_data = preprocessing.normalize(Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LDngxlyzoJbb"
      },
      "outputs": [],
      "source": [
        "#convert Data to Tensor\n",
        "#height = width = 600\n",
        "#X = np.asarray(Data).reshape(len(Data),height,width,1)\n",
        "X = np.asarray(Data).reshape(len(Data),number_of_samples,1)\n",
        "y = to_categorical(Target,num_classes=2)\n",
        "#y = np.asarray(Target).astype('float32')\n",
        "X_test = np.asarray(Data_test).reshape(len(Data_test),number_of_samples,1)\n",
        "y_test = to_categorical(Target_test,num_classes=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8lBqf52pCvF",
        "outputId": "4767f1ee-048c-402c-aa29-1fda8186d713"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "y[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hSOzdRuqQhv9"
      },
      "outputs": [],
      "source": [
        "# myInput=layers.Input(shape=(height,width,1))\n",
        "# conv1=Conv2D(16,3, activation='relu',padding='same')(myInput)\n",
        "# max1=MaxPooling2D(2)(conv1)\n",
        "# conv2=Conv2D(16,3, activation='relu',padding='same')(max1)\n",
        "# max2=MaxPooling2D(2)(conv2)\n",
        "# flat=Flatten()(max2)\n",
        "# dens1 =Dense(50, activation='relu')(flat)\n",
        "# dens2 =Dense(10, activation='relu')(dens1)\n",
        "# out_layer =Dense(1, activation='sigmoid')(dens2)\n",
        "# model_CNN = Model(myInput, out_layer)\n",
        "# model_CNN.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qiyAoOSAlMsN"
      },
      "outputs": [],
      "source": [
        "#simpler model\n",
        "# myInput=layers.Input(shape=(height,width,1))\n",
        "# conv1=Conv2D(8,3, activation='relu',padding='same')(myInput)\n",
        "# max1=MaxPooling2D(2)(conv1)\n",
        "# conv2=Conv2D(8,3, activation='relu',padding='same')(max1)\n",
        "# max2=MaxPooling2D(2)(conv2)\n",
        "# flat=Flatten()(max2)\n",
        "# dens1 =Dense(10, activation='relu')(flat)\n",
        "\n",
        "# out_layer =Dense(2, activation='softmax')(dens1)\n",
        "# model_CNN = Model(myInput, out_layer)\n",
        "# model_CNN.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#First Model with accuracy 94%"
      ],
      "metadata": {
        "id": "jy-CwgG3ul_t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XCqpYkkN3zX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b4c6a6-604d-48cf-8a7a-3a9f7723facb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 160000, 1)]       0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 160000, 64)        1088      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 10000, 64)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10000, 64)         0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 10000, 64)         65600     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 625, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 625, 64)           0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 40000)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               4000100   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 25)                2525      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 52        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,069,365\n",
            "Trainable params: 4,069,365\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.backend import dropout\n",
        "myInput=layers.Input(shape=(number_of_samples,1))\n",
        "conv1=Conv1D(64,16, activation='relu',padding='same')(myInput)\n",
        "max1=MaxPooling1D(16)(conv1)\n",
        "drop1 =Dropout(.2)(max1)\n",
        "conv2=Conv1D(64,16, activation='relu',padding='same')(drop1)\n",
        "max2=MaxPooling1D(16)(conv2)\n",
        "drop2 = Dropout(.2)(max2)\n",
        "flat=Flatten()(drop2)\n",
        "dens1 =Dense(100, activation='relu')(flat)\n",
        "dens2 =Dense(25, activation='relu')(dens1)\n",
        "out_layer =Dense(2, activation='softmax')(dens2)\n",
        "model_CNN = Model(myInput, out_layer)\n",
        "model_CNN.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.backend import dropout\n",
        "# myInput=layers.Input(shape=(number_of_samples,1))\n",
        "# conv1=Conv1D(64,32, activation='relu',padding='same')(myInput)\n",
        "# max1=MaxPooling1D(32)(conv1)\n",
        "# drop1 =Dropout(.2)(max1)\n",
        "# conv2=Conv1D(64,32, activation='relu',padding='same')(drop1)\n",
        "# max2=MaxPooling1D(32)(conv2)\n",
        "# drop2 = Dropout(.2)(max2)\n",
        "# flat=Flatten()(drop2)\n",
        "# dens1 =Dense(100, activation='relu')(flat)\n",
        "# dens2 =Dense(25, activation='relu')(dens1)\n",
        "# out_layer =Dense(2, activation='softmax')(dens2)\n",
        "# model_CNN = Model(myInput, out_layer)\n",
        "# model_CNN.summary()"
      ],
      "metadata": {
        "id": "wLTX6MO1uhdW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gI8o9EpWSPDa"
      },
      "outputs": [],
      "source": [
        "model_CNN.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split\n",
        "X_train,X_valid,y_train, y_valid = train_test_split(X,y,test_size=.2)"
      ],
      "metadata": {
        "id": "qD31zyKRx93K"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#whether shuffling works\n",
        "# a = y_test\n",
        "# noone = 0\n",
        "# for i in range(a.shape[0]):\n",
        "#   if a[i][0] == 1 :\n",
        "#     noone += 1\n",
        "# print(noone/a.shape[0])"
      ],
      "metadata": {
        "id": "mNPOCaF7ydcL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD0Q4GsgS_iN",
        "outputId": "beba86ae-4ddf-4f16-b238-aeb7a073bbcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "59/59 [==============================] - 29s 299ms/step - loss: 0.6774 - accuracy: 0.5333 - val_loss: 0.6288 - val_accuracy: 0.6468\n",
            "Epoch 2/20\n",
            "59/59 [==============================] - 16s 273ms/step - loss: 0.5910 - accuracy: 0.6424 - val_loss: 0.6701 - val_accuracy: 0.5447\n",
            "Epoch 3/20\n",
            "59/59 [==============================] - 16s 273ms/step - loss: 0.5618 - accuracy: 0.6551 - val_loss: 0.5257 - val_accuracy: 0.6936\n",
            "Epoch 4/20\n",
            "59/59 [==============================] - 16s 273ms/step - loss: 0.5142 - accuracy: 0.6982 - val_loss: 0.5104 - val_accuracy: 0.7362\n",
            "Epoch 5/20\n",
            "59/59 [==============================] - 16s 274ms/step - loss: 0.4846 - accuracy: 0.7653 - val_loss: 0.4765 - val_accuracy: 0.7447\n",
            "Epoch 6/20\n",
            "59/59 [==============================] - 16s 274ms/step - loss: 0.4279 - accuracy: 0.8079 - val_loss: 0.4680 - val_accuracy: 0.8106\n",
            "Epoch 7/20\n",
            "59/59 [==============================] - 15s 258ms/step - loss: 0.4013 - accuracy: 0.8276 - val_loss: 0.3884 - val_accuracy: 0.8170\n",
            "Epoch 8/20\n",
            "59/59 [==============================] - 16s 273ms/step - loss: 0.3656 - accuracy: 0.8435 - val_loss: 0.3899 - val_accuracy: 0.8170\n",
            "Epoch 9/20\n",
            "59/59 [==============================] - 15s 257ms/step - loss: 0.3029 - accuracy: 0.8696 - val_loss: 0.5924 - val_accuracy: 0.7511\n",
            "Epoch 10/20\n",
            "59/59 [==============================] - 16s 273ms/step - loss: 0.2604 - accuracy: 0.8999 - val_loss: 0.5350 - val_accuracy: 0.7957\n",
            "Epoch 11/20\n",
            "59/59 [==============================] - 15s 258ms/step - loss: 0.2470 - accuracy: 0.9042 - val_loss: 0.3030 - val_accuracy: 0.8872\n",
            "Epoch 12/20\n",
            "38/59 [==================>...........] - ETA: 4s - loss: 0.1611 - accuracy: 0.9334"
          ]
        }
      ],
      "source": [
        "verbose, epochs, batch_size = 1, 20, 32\n",
        "# fit network\n",
        "history = model_CNN.fit(X_train,y_train, epochs=epochs, batch_size=batch_size,validation_data= (X_valid,y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LboBSNfaAGdq"
      },
      "outputs": [],
      "source": [
        "model_CNN.evaluate(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "history_dict = history.history\n",
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1,len(loss_values)+1)\n",
        "plt.plot(epochs,loss_values,\"bo\",label = \"Training loss\")\n",
        "plt.plot(epochs,val_loss_values,\"b\", label = \"Validation loss\")\n",
        "plt.title(\"Training and Validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0kAd_04wrxMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_values = history_dict[\"accuracy\"]\n",
        "val_acc_values = history_dict[\"val_accuracy\"]\n",
        "epochs = range(1,len(acc_values)+1)\n",
        "plt.plot(epochs,acc_values,\"bo\",label = \"Training accuracy\")\n",
        "plt.plot(epochs,val_acc_values,\"b\", label = \"Validation accuracy\")\n",
        "plt.title(\"Training and Validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HWwamHe6tekm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPDev7RnR9eH5YuyhR6LLie",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}